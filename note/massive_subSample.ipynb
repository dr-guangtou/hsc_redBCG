{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from __future__ import (division, print_function)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import fnmatch\n",
    "import warnings\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "try:\n",
    "    from scipy.stats import scoreatpercentile\n",
    "except:\n",
    "    scoreatpercentile = False\n",
    "from scipy.interpolate import interp1d\n",
    "import cPickle as pickle\n",
    "\n",
    "# Astropy\n",
    "from astropy.io import fits\n",
    "from astropy    import units as u\n",
    "from astropy.stats import sigma_clip\n",
    "from astropy.table import Table, Column\n",
    "from astropy.utils.console import ProgressBar\n",
    "\n",
    "# AstroML\n",
    "from astroML.plotting import hist\n",
    "\n",
    "# Matplotlib related\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "# Matplotlib default settings\n",
    "rcdef = plt.rcParams.copy()\n",
    "pylab.rcParams['figure.figsize'] = 12, 10\n",
    "pylab.rcParams['xtick.major.size'] = 8.0\n",
    "pylab.rcParams['xtick.major.width'] = 2.5\n",
    "pylab.rcParams['xtick.minor.size'] = 4.0\n",
    "pylab.rcParams['xtick.minor.width'] = 2.5\n",
    "pylab.rcParams['ytick.major.size'] = 8.0\n",
    "pylab.rcParams['ytick.major.width'] = 2.5\n",
    "pylab.rcParams['ytick.minor.size'] = 4.0\n",
    "pylab.rcParams['ytick.minor.width'] = 2.5\n",
    "\n",
    "# Personal\n",
    "import hscUtils as hUtil\n",
    "import galSBP\n",
    "import coaddCutoutGalfitSimple as gSimple \n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "import cosmology\n",
    "c=cosmology.Cosmo(H0=70.0, omega_m=0.3, omega_l=0.7, flat=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Absolute magnitude of sun in HSC filters\n",
    "\n",
    "# Actuall borrowed from DES filters\n",
    "# Values from magsun.data in FSPS\n",
    "amag_sun_des_g = 5.08\n",
    "amag_sun_des_r = 4.62\n",
    "amag_sun_des_i = 4.52\n",
    "amag_sun_des_z = 4.52\n",
    "amag_sun_des_y = 4.51\n",
    "\n",
    "# Based on http://www.baryons.org/ezgal/filters.php\n",
    "amag_sun_ukiss_y = 4.515\n",
    "\n",
    "# Extinction correction factor for HSC \n",
    "## A\\_lambda = Coeff * E(B-V) \n",
    "\n",
    "a_hsc_g = 3.233\n",
    "a_hsc_r = 2.291 \n",
    "a_hsc_i = 1.635\n",
    "a_hsc_z = 1.261\n",
    "a_hsc_y = 1.076\n",
    "\n",
    "# \n",
    "SIGMA1 = 0.3173\n",
    "SIGMA2 = 0.0455\n",
    "SIGMA3 = 0.0027\n",
    "\n",
    "RSMA_COMMON = np.arange(0.4, 4.2, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for Get Bootstrap mean or median \n",
    "def _confidence_interval_1d(A, alpha=.05, metric=np.mean, numResamples=10000, interpolate=True):\n",
    "    \"\"\"Calculates bootstrap confidence interval along one dimensional array\"\"\"\n",
    "    \n",
    "    if not isinstance(alpha, collections.Iterable):\n",
    "        alpha = np.array([alpha])\n",
    "\n",
    "    N = len(A)\n",
    "    resampleInds = np.random.randint(0, N, (numResamples,N))\n",
    "    metricOfResampled = metric(A[resampleInds], axis=-1)\n",
    "\n",
    "    confidenceInterval = np.zeros(2*len(alpha),dtype='float')\n",
    "    \n",
    "    if interpolate:\n",
    "        for thisAlphaInd, thisAlpha in enumerate(alpha):\n",
    "            confidenceInterval[2*thisAlphaInd] = scoreatpercentile(metricOfResampled, \n",
    "                                                                   thisAlpha*100/2.0)\n",
    "            confidenceInterval[2*thisAlphaInd+1] = scoreatpercentile(metricOfResampled, \n",
    "                                                                     100-thisAlpha*100/2.0)\n",
    "    else:\n",
    "        sortedMetricOfResampled = np.sort(metricOfResampled)\n",
    "        for thisAlphaInd, thisAlpha in enumerate(alpha):\n",
    "            confidenceInterval[2*thisAlphaInd] = sortedMetricOfResampled[int(round(thisAlpha*numResamples/2.0))]\n",
    "            confidenceInterval[2*thisAlphaInd+1] = sortedMetricOfResampled[int(round(numResamples - \n",
    "                                                                                     thisAlpha*numResamples/2.0))]\n",
    "    return confidenceInterval\n",
    "    \n",
    "def _ma_confidence_interval_1d(A, alpha=.05, metric=np.mean, numResamples=10000, interpolate=True):\n",
    "    A = np.ma.masked_invalid(A, copy=True)\n",
    "    A = A.compressed()\n",
    "    confidenceInterval = _confidence_interval_1d(A, alpha, metric, numResamples, interpolate)\n",
    "    return confidenceInterval\n",
    "\n",
    "def confidence_interval(A, axis=None, alpha=.05, metric=np.mean, numResamples=10000, interpolate=True):\n",
    "    \"\"\"Return the bootstrap confidence interval of an array or along an axis ignoring NaNs and masked elements.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : array_like\n",
    "        Array containing numbers whose confidence interval is desired. \n",
    "    axis : int, optional\n",
    "        Axis along which the confidence interval is computed.\n",
    "        The default is to compute the confidence interval of the flattened array.\n",
    "    alpha: float or array, optional\n",
    "        confidence level of confidence interval. 100.0*(1-alpha) percent confidence \n",
    "        interval will be returned.\n",
    "        If length-n array, n confidence intervals will be computed\n",
    "        The default is .05\n",
    "    metric : numpy function, optional\n",
    "        metric to calculate confidence interval for.\n",
    "        The default is numpy.mean\n",
    "    numResamples : int, optional\n",
    "        number of bootstrap samples. The default is 10000.\n",
    "    interpolate: bool, optional\n",
    "        uses scipy.stats.scoreatpercentile to interpolate between bootstrap samples \n",
    "        if alpha*numResamples/2.0 is not integer.\n",
    "        The default is True\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    confidenceInterval : ndarray\n",
    "    An array with the same shape as `A`, with the specified axis replaced by one twice the length of the alpha\n",
    "    If `A` is a 0-d array, or if axis is None, a length-2 ndarray is returned.\n",
    "    \"\"\"\n",
    "    if interpolate is True and scoreatpercentile is False:\n",
    "        print(\"need scipy to interpolate between values\")\n",
    "        interpolate = False\n",
    "    A = A.copy()\n",
    "    if axis is None:\n",
    "        A = A.ravel()\n",
    "        outA = _ma_confidence_interval_1d(A, alpha, metric, numResamples, interpolate)\n",
    "    else:\n",
    "        outA = np.apply_along_axis(_ma_confidence_interval_1d, axis, A, alpha, \n",
    "                                   metric, numResamples, interpolate)\n",
    "        \n",
    "    return outA\n",
    "\n",
    "def normProf(sma, sbp, minSma, maxSma, divide=False): \n",
    "    \"\"\"\n",
    "    Naive method to normalize the profile. \n",
    "    \n",
    "    Parameters: \n",
    "        sbp    : Array for surface brightness profile \n",
    "        sma    : Radius range \n",
    "        minSma : Minimum SMA\n",
    "        maxSma   Maximum SMA\n",
    "    \"\"\"\n",
    "    offset = np.nanmedian(sbp[(sma >= minSma) & \n",
    "                              (sma <= maxSma)])\n",
    "    if divide: \n",
    "        return (sbp / offset)\n",
    "    else:\n",
    "        return (sbp-offset)\n",
    "    \n",
    "    \n",
    "def pixKpc(redshift, pix=0.168, show=True, npix=1.0):\n",
    "    \"\"\"\n",
    "    Get the corresponding Kpc size of a pixel.  \n",
    "    \n",
    "    Parameters: \n",
    "    \"\"\"\n",
    "    pixKpc = pix * npix * hUtil.cosmoScale(redshift)\n",
    "\n",
    "    if show:\n",
    "        print(\"# %d pixel(s) = %6.3f Kpc\" % (npix, pixKpc))\n",
    "        \n",
    "    return pixKpc\n",
    "\n",
    "\n",
    "def logAdd(para1, para2):\n",
    "    \"\"\" Useful for adding magnitudes. \"\"\"\n",
    "    return np.log10((10.0 ** np.asarray(para1)) + \n",
    "                    (10.0 ** np.asarray(para2)))\n",
    "\n",
    "\n",
    "def errAdd(err1, err2):\n",
    "    \"\"\"Add error quadral...\"\"\"\n",
    "    return np.sqrt((err1 ** 2.0) + \n",
    "                   (err2 ** 2.0))\n",
    "\n",
    "\n",
    "def toColorArr(data, bottom=None, top=None):\n",
    "    \"\"\" \n",
    "    Convert a data array to \"color array\" (between 0 and 1). \n",
    "    \n",
    "    Parameters:\n",
    "        bottom, top  : \n",
    "    \"\"\"\n",
    "    if top is not None:\n",
    "        data[data >= top] = top\n",
    "    if bottom is not None:\n",
    "        data[data <= bottom] = bottom\n",
    "        \n",
    "    return ((data - np.nanmin(data)) / \n",
    "            (np.nanmax(data) - np.nanmin(data))) * 255.0\n",
    "\n",
    "\n",
    "def getLuminosity(mag, redshift, extinction=None, \n",
    "                  amag_sun=None):\n",
    "    \"\"\"Get the absolute magnitude or luminosity.\"\"\"\n",
    "    distmod = hUtil.cosmoDistMod(redshift)\n",
    "    absMag = (mag - distmod)\n",
    "    if extinction is not None: \n",
    "        absMag -= extinction \n",
    "    if amag_sun is not None: \n",
    "        absMag = ((amag_sun - absMag) / 2.5)\n",
    "    \n",
    "    return absMag\n",
    "\n",
    "def getStackProfiles(sample, loc, name='GAMA', \n",
    "                     idCol='ID_USE', tabCol='sum_tab', save=True):\n",
    "    \"\"\"Get the stacks of the profiles.\"\"\"\n",
    "    print(\"## Sample %s : Will deal with %d galaxies\" % (name, len(sample)))\n",
    "    profiles = []\n",
    "    with ProgressBar(len(sample), ipython_widget=True) as bar:\n",
    "        for g in sample:\n",
    "            try:\n",
    "                gFile = os.path.join(loc, g['sum_tab'].replace('./', '')).strip()\n",
    "                gProf = Table.read(gFile, format='fits')\n",
    "                \"\"\" Add extra information \"\"\"\n",
    "                try: \n",
    "                    gProf.meta['KCORRECT_I'] = g['KCORRECT_I']\n",
    "                    gProf.meta['KCORRECT_b_I'] = g['KCORRECT_b_I']\n",
    "                    gProf.meta['KCORRECT_c_I'] = g['KCORRECT_c_I']\n",
    "                    gProf.meta['KCORRECT_G'] = g['KCORRECT_G']\n",
    "                    gProf.meta['KCORRECT_b_G'] = g['KCORRECT_b_G']\n",
    "                    gProf.meta['KCORRECT_c_G'] = g['KCORRECT_c_G']\n",
    "                    gProf.meta['KCORRECT_R'] = g['KCORRECT_R']\n",
    "                    gProf.meta['KCORRECT_b_R'] = g['KCORRECT_b_R']\n",
    "                    gProf.meta['KCORRECT_c_R'] = g['KCORRECT_c_R']\n",
    "                    gProf.meta['KCORRECT_Z'] = g['KCORRECT_Z']\n",
    "                    gProf.meta['KCORRECT_b_Z'] = g['KCORRECT_b_Z']\n",
    "                    gProf.meta['KCORRECT_c_Z'] = g['KCORRECT_c_Z']\n",
    "                    gProf.meta['KCORRECT_Y'] = g['KCORRECT_Y']\n",
    "                    gProf.meta['KCORRECT_b_Y'] = g['KCORRECT_b_Y']\n",
    "                    gProf.meta['KCORRECT_c_Y'] = g['KCORRECT_c_Y']\n",
    "                    gProf.meta['LOGM2LI_A'] = g['logm2lI_A']\n",
    "                    gProf.meta['LOGM2LI_B'] = g['logm2lI_B']\n",
    "                    gProf.meta['LOGM2LI_C'] = g['logm2lI_C']\n",
    "                    gProf.meta['LUM_100'] = g['lum_100']\n",
    "                    gProf.meta['LUM_120'] = g['lum_120']\n",
    "                except Exception:\n",
    "                    print(\"## WARNING: Some metadata may not be available !\")\n",
    "                    continue\n",
    "            except Exception:\n",
    "                print(\"## Missing: %s\" % gFile)\n",
    "                continue \n",
    "            profiles.append(gProf)\n",
    "            bar.update()\n",
    "    \n",
    "    if save: \n",
    "        outPkl = os.path.join(loc, (name + '_profs.pkl'))\n",
    "        hUtil.saveToPickle(profiles, outPkl)\n",
    "        print(\"## Save %s to %s\" % (name, outPkl))\n",
    "        \n",
    "    return profiles\n",
    "\n",
    "\n",
    "def organizeSbp(profiles, col1='muI1', col2='KCORRECT_c_I', \n",
    "                kind='sbp', norm=False, r1=9.9, r2=10.1, divide=False,\n",
    "                col3=None, col4=None, justStack=False,\n",
    "                sun1=amag_sun_des_g, sun2=amag_sun_des_r):\n",
    "    \"\"\" Get the stack of individual profiels, and their med/avg. \"\"\"\n",
    "    if kind.strip() == 'sbp':\n",
    "        if col2 is not None: \n",
    "            if norm:\n",
    "                stack = np.vstack(normProf(p['rKpc'], \n",
    "                                           np.asarray(p[col1] + (p.meta[col2] / 2.5)), \n",
    "                                           r1, r2, divide=divide) \n",
    "                                  for p in profiles)\n",
    "            else:\n",
    "                stack = np.vstack(np.asarray(p[col1] + (p.meta[col2] / 2.5)) \n",
    "                                  for p in profiles)\n",
    "        else: \n",
    "            print(\"## NO KCORRECTION APPLIED !!\")            \n",
    "            if norm:\n",
    "                stack = np.vstack(normProf(p['rKpc'], p[col1], \n",
    "                                           r1, r2, divide=divide) \n",
    "                                  for p in profiles)\n",
    "            else:\n",
    "                stack = np.vstack(np.asarray(p[col1]) for p in profiles)\n",
    "    elif kind.strip() == 'mass':\n",
    "        if norm:\n",
    "            stack = np.vstack(normProf(p['rKpc'], \n",
    "                                       np.asarray(p[col1] + p.meta[col2]), \n",
    "                                       r1, r2, divide=divide) for p in profiles)\n",
    "        else: \n",
    "            stack = np.vstack(np.asarray(p[col1] + p.meta[col2]) for p in profiles)\n",
    "    elif kind.strip() == 'color':\n",
    "        cSun = (sun1 - sun2)\n",
    "        if col3 is None or col4 is None:\n",
    "            print(\"## NO KCORRECTION APPLIED !!\")\n",
    "            if norm:\n",
    "                stack = np.vstack(normProf(p['rKpc'], \n",
    "                                           np.asarray(cSun - 2.5 * (p[col1] - p[col2])), \n",
    "                                           r1, r2, divide=divide) for p in profiles)\n",
    "            else: \n",
    "                stack = np.vstack(np.asarray(cSun - 2.5 *(p[col1] - p[col2])) for p in profiles)\n",
    "        else:\n",
    "            if norm:\n",
    "                stack = np.vstack(normProf(p['rKpc'], \n",
    "                                           np.asarray(cSun - 2.5 * (p[col1] - p[col2]) -\n",
    "                                                      (p.meta[col3] - p.meta[col4])), \n",
    "                                           r1, r2, divide=divide) for p in profiles)\n",
    "            else: \n",
    "                stack = np.vstack(np.asarray(cSun - 2.5 * (p[col1] - p[col2]) -\n",
    "                                             (p.meta[col3] - p.meta[col4])) \n",
    "                                  for p in profiles)\n",
    "    elif kind.strip() == 'lum':\n",
    "        if col2 is None:\n",
    "            stack = np.vstack(np.asarray(p[col1]) for p in profiles)\n",
    "        else:\n",
    "            stack = np.vstack(np.asarray(p[col1] - p.meta[col2]) for p in profiles)\n",
    "    else: \n",
    "        raise Exception(\"## WRONG KIND !!\")\n",
    "        \n",
    "    if not justStack:\n",
    "        \"\"\" Get the median and 1-sigma confidence range \"\"\"\n",
    "        medProf = confidence_interval(stack, axis=0, alpha=np.asarray([SIGMA1, 1.0]), \n",
    "                                      metric=np.nanmedian, numResamples=1000, \n",
    "                                      interpolate=True) \n",
    "        avgProf = confidence_interval(stack, axis=0, alpha=np.asarray([SIGMA1, 1.0]), \n",
    "                                      metric=np.nanmean, numResamples=1000, \n",
    "                                      interpolate=True) \n",
    "        stdProf = confidence_interval(stack, axis=0, alpha=np.asarray([SIGMA1, 1.0]), \n",
    "                                      metric=np.nanstd, numResamples=1000, \n",
    "                                      interpolate=True) \n",
    "        return stack, medProf, avgProf, stdProf\n",
    "    else: \n",
    "        return stack\n",
    "    \n",
    "\n",
    "def loadPkl(filename):\n",
    "    try:\n",
    "        import cPickle as pickle\n",
    "    except:\n",
    "        warnings.warn(\"## cPickle is not available!!\")\n",
    "        import pickle\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        pklFile = open(filename, 'rb')\n",
    "        data = pickle.load(pklFile)    \n",
    "        pklFile.close()\n",
    "    \n",
    "        return data\n",
    "    else: \n",
    "        warnings.warn(\"## Can not find %s, return None\" % filename)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Deal with 219 galaxies in redBCH sample\n",
      "## Deal with 1670 galaxies in redMEM sample\n",
      "## Deal with 9212 galaxies in GAMA sample\n"
     ]
    }
   ],
   "source": [
    "newDir = '/Users/songhuang/work/hscs/gama_massive/sbp/'\n",
    "\n",
    "bcgFile = 'redbcg_1d_160211.fits'\n",
    "memFile = 'redmem_1d_160211.fits'\n",
    "gamaFile = 'gama_1d_160211.fits'\n",
    "\n",
    "try:\n",
    "    bcgTab\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    del bcgTab\n",
    "    \n",
    "try:\n",
    "    memTab\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    del memTab    \n",
    "    \n",
    "try:\n",
    "    gamaTab\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    del gamaTab\n",
    "\n",
    "# Two summary catalogs\n",
    "bcgCat = os.path.join(newDir, bcgFile)\n",
    "memCat = os.path.join(newDir, memFile)\n",
    "gamaCat = os.path.join(newDir, gamaFile)\n",
    "\n",
    "if not os.path.isfile(bcgCat):\n",
    "    raise Exception(\"## Can not find catalog for BCGs : %s\" % bcgCat)\n",
    "else: \n",
    "    bcgTab = Table.read(bcgCat, format='fits')\n",
    "\n",
    "if not os.path.isfile(memCat):\n",
    "    raise Exception(\"## Can not find catalog for cluster members : %s\" % memCat)\n",
    "else: \n",
    "    memTab = Table.read(memCat, format='fits')\n",
    "    \n",
    "if not os.path.isfile(gamaCat):\n",
    "    raise Exception(\"## Can not find catalog for GAMA galaxies : %s\" % gamaCat)\n",
    "else: \n",
    "    gamaTab = Table.read(gamaCat, format='fits')\n",
    "    \n",
    "print(\"## Deal with %i galaxies in redBCH sample\" % len(bcgTab))\n",
    "print(\"## Deal with %i galaxies in redMEM sample\" % len(memTab))\n",
    "print(\"## Deal with %i galaxies in GAMA sample\" % len(gamaTab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4601\n",
      "264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:7: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    }
   ],
   "source": [
    "gamaClean = gamaTab[(gamaTab['c82_120'] >= 5.0) & (gamaTab['gz_kC'] >= 1.5) &\n",
    "                    (gamaTab['ur_rest_sed'] >= 2.0)]\n",
    "\n",
    "print(len(gamaClean))\n",
    "\n",
    "memClean = memTab[(memTab['c82_120'] >= 5.0) & (memTab['gz_kC'] >= 1.5) &\n",
    "                  (memTab['ur_rest_sed'] >= 2.0)]\n",
    "\n",
    "print(len(memClean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Luminosity Subsamples\n",
    "\n",
    "## Total Luminosity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################################\n",
      "## 0.2 < z < 0.4 ; 11.2 < logL* < 11.4 using SBP Luminosity\n",
      "\n",
      "## GAMA L1 : 436, 436 galaxies\n",
      "## BCG L1  : 47, 48 galaxies\n",
      "## MEM L1  : 38, 38 galaxies\n",
      "\n",
      "## GAMA - Median redshift :  0.325859993696 0.325114995241\n",
      "## BCG  - Median redshift :  0.302599996328 0.303484976292\n",
      "## MEM  - Median redshift :  0.318525016308 0.318525016308\n",
      "\n",
      "## GAMA - Median logL_sbp :  11.2609176636 11.2609176636\n",
      "## BCG  - Median logL_sbp :  11.2946062088 11.2946062088\n",
      "## MEM  - Median logL_sbp :  11.2562122345 11.2562122345\n",
      "##########################################################################\n",
      "\n",
      "## bcgL1a_pcen : 39 out of 47\n",
      "## bcgL1c_pcen : 40 out of 48\n",
      "## BCG/PCEN - Median redshift :  0.296535611153 0.296876251698\n",
      "## BCG/PCEN - Median logL_sbp :  11.2940378189 11.2976369858\n",
      "##########################################################################\n",
      "\n",
      "## gamaL1a_pcen : 400 out of 436\n",
      "## gamaL1c_pcen : 398 out of 436\n",
      "## GAMA/USE - Median redshift :  0.323960006237 0.323805004358\n",
      "## GAMA/USE - Median logL_sbp :  11.2645549774 11.2629966736\n",
      "##########################################################################\n"
     ]
    }
   ],
   "source": [
    "# Luminosity 1\n",
    "print(\"##########################################################################\")\n",
    "print(\"## 0.2 < z < 0.4 ; 11.2 < logL* < 11.4 using SBP Luminosity\")\n",
    "\n",
    "## Using lum100; model C\n",
    "gamaL1c = gamaTab[(gamaTab['Z'] >= 0.20) & (gamaTab['Z'] <= 0.40) &\n",
    "                  (gamaTab['lum_100'] + (gamaTab['KCORRECT_c_I'] / 2.5) >= 11.2) & \n",
    "                  (gamaTab['lum_100'] + (gamaTab['KCORRECT_c_I'] / 2.5) <= 11.4)]\n",
    "\n",
    "memL1c = memTab[(memTab['Z'] >= 0.20) & (memTab['Z'] <= 0.40) &\n",
    "                (memTab['lum_100'] + (memTab['KCORRECT_c_I'] / 2.5) >= 11.2) & \n",
    "                (memTab['lum_100'] + (memTab['KCORRECT_c_I'] / 2.5) <= 11.4)]\n",
    "\n",
    "bcgL1c = bcgTab[(bcgTab['Z'] >= 0.20) & (bcgTab['Z'] <= 0.40) & \n",
    "                (bcgTab['lum_100'] + (bcgTab['KCORRECT_c_I'] / 2.5) >= 11.2) & \n",
    "                (bcgTab['lum_100'] + (bcgTab['KCORRECT_c_I'] / 2.5) <= 11.4)]\n",
    "\n",
    "## Using lum100; model A\n",
    "gamaL1a = gamaTab[(gamaTab['Z'] >= 0.20) & (gamaTab['Z'] <= 0.40) &\n",
    "                  (gamaTab['lum_100'] + (gamaTab['KCORRECT_I'] / 2.5) >= 11.2) & \n",
    "                  (gamaTab['lum_100'] + (gamaTab['KCORRECT_I'] / 2.5) <= 11.4)]\n",
    "\n",
    "memL1a = memTab[(memTab['Z'] >= 0.20) & (memTab['Z'] <= 0.40) &\n",
    "                (memTab['lum_100'] + (memTab['KCORRECT_I'] / 2.5) >= 11.2) & \n",
    "                (memTab['lum_100'] + (memTab['KCORRECT_I'] / 2.5) <= 11.4)]\n",
    "\n",
    "bcgL1a = bcgTab[(bcgTab['Z'] >= 0.20) & (bcgTab['Z'] <= 0.40) & \n",
    "                (bcgTab['lum_100'] + (bcgTab['KCORRECT_I'] / 2.5) >= 11.2) & \n",
    "                (bcgTab['lum_100'] + (bcgTab['KCORRECT_I'] / 2.5) <= 11.4)]\n",
    "\n",
    "print(\"\\n## GAMA L1 : %i, %i galaxies\" % (len(gamaL1a), len(gamaL1c)))\n",
    "print(\"## BCG L1  : %i, %i galaxies\" % (len(bcgL1a), len(bcgL1c)))\n",
    "print(\"## MEM L1  : %i, %i galaxies\" % (len(memL1a), len(memL1c)))\n",
    "\n",
    "print(\"\\n## GAMA - Median redshift : \", np.nanmedian(gamaL1a['Z']), np.nanmedian(gamaL1c['Z']))\n",
    "print(\"## BCG  - Median redshift : \", np.nanmedian(bcgL1a['Z']), np.nanmedian(bcgL1c['Z']))\n",
    "print(\"## MEM  - Median redshift : \", np.nanmedian(memL1a['Z']), np.nanmedian(memL1c['Z']))\n",
    "\n",
    "print(\"\\n## GAMA - Median logL_sbp : \", (np.nanmedian(gamaL1c['lum_100'] + (gamaL1c['KCORRECT_c_I'] / 2.5))),\n",
    "      (np.nanmedian(gamaL1c['lum_100'] + (gamaL1c['KCORRECT_c_I'] / 2.5))))\n",
    "print(\"## BCG  - Median logL_sbp : \", (np.nanmedian(bcgL1c['lum_100'] + (bcgL1c['KCORRECT_c_I'] / 2.5))),\n",
    "      (np.nanmedian(bcgL1c['lum_100'] + (bcgL1c['KCORRECT_c_I'] / 2.5))))\n",
    "print(\"## MEM  - Median logL_sbp : \", (np.nanmedian(memL1c['lum_100'] + (memL1c['KCORRECT_c_I'] / 2.5))),\n",
    "      (np.nanmedian(memL1c['lum_100'] + (memL1c['KCORRECT_c_I'] / 2.5))))     \n",
    "print(\"##########################################################################\\n\")\n",
    "\n",
    "\n",
    "\n",
    "bcgL1a_pcen = bcgL1a[bcgL1a['P_CEN_1'] >= 0.8]\n",
    "bcgL1c_pcen = bcgL1c[bcgL1c['P_CEN_1'] >= 0.8]\n",
    "\n",
    "print(\"## bcgL1a_pcen : %d out of %d\" % (len(bcgL1a_pcen), len(bcgL1a)))\n",
    "print(\"## bcgL1c_pcen : %d out of %d\" % (len(bcgL1c_pcen), len(bcgL1c)))\n",
    "\n",
    "print(\"## BCG/PCEN - Median redshift : \", np.nanmedian(bcgL1a_pcen['Z']), np.nanmedian(bcgL1c_pcen['Z']))\n",
    "\n",
    "print(\"## BCG/PCEN - Median logL_sbp : \", \n",
    "      (np.nanmedian(bcgL1a_pcen['lum_100'] + (bcgL1a_pcen['KCORRECT_I'] / 2.5))),\n",
    "      (np.nanmedian(bcgL1c_pcen['lum_100'] + (bcgL1c_pcen['KCORRECT_c_I'] / 2.5))))\n",
    "\n",
    "print(\"##########################################################################\\n\")\n",
    "\n",
    "gamaL1c_use = gamaL1c[(gamaL1c['c82_120'] >=5.0) & (gamaL1c['gz_kC'] >= 1.5)]\n",
    "gamaL1a_use = gamaL1a[(gamaL1a['c82_120'] >=5.0) & (gamaL1a['gz_kA'] >= 1.5)]\n",
    "\n",
    "print(\"## gamaL1a_pcen : %d out of %d\" % (len(gamaL1a_use), len(gamaL1a)))\n",
    "print(\"## gamaL1c_pcen : %d out of %d\" % (len(gamaL1c_use), len(gamaL1c)))\n",
    "\n",
    "\n",
    "print(\"## GAMA/USE - Median redshift : \", np.nanmedian(gamaL1a_use['Z']), \n",
    "      np.nanmedian(gamaL1c_use['Z']))\n",
    "\n",
    "print(\"## GAMA/USE - Median logL_sbp : \", \n",
    "      (np.nanmedian(gamaL1a_use['lum_100'] + (gamaL1a_use['KCORRECT_I'] / 2.5))),\n",
    "      (np.nanmedian(gamaL1c_use['lum_100'] + (gamaL1c_use['KCORRECT_c_I'] / 2.5))))\n",
    "\n",
    "print(\"##########################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################################\n",
      "## 0.2 < z < 0.4 ; 11.4 < logL* < 11.6 using SBP Luminosity\n",
      "\n",
      "## GAMA L2 : 118, 120 galaxies\n",
      "## BCG L2  : 35, 34 galaxies\n",
      "## MEM L2  : 1, 1 galaxies\n",
      "\n",
      "## GAMA - Median redshift :  0.42553499341 0.42553499341\n",
      "## BCG  - Median redshift :  0.388627022505 0.389091789722\n",
      "## MEM  - Median redshift :  0.312359988689 0.312359988689\n",
      "\n",
      "## GAMA - Median logL_sbp :  11.444984436 11.444984436\n",
      "## BCG  - Median logL_sbp :  11.477022171 11.477022171\n",
      "## MEM  - Median logL_sbp :  11.4008026123 11.4008026123\n",
      "##########################################################################\n",
      "\n",
      "## bcgL2a_pcen : 32 out of 35\n",
      "## bcgL2c_pcen : 31 out of 34\n",
      "## BCG/PCEN - Median redshift :  0.38480001688 0.387259989977\n",
      "## BCG/PCEN - Median logL_sbp :  11.473780632 11.4755144119\n",
      "##########################################################################\n",
      "\n",
      "## gamaL2a_pcen : 112 out of 118\n",
      "## gamaL2c_pcen : 114 out of 120\n",
      "## GAMA/USE - Median redshift :  0.419903546572 0.424445003271\n",
      "## GAMA/USE - Median logL_sbp :  11.4419984818 11.4442901611\n",
      "##########################################################################\n"
     ]
    }
   ],
   "source": [
    "# Luminosity 1\n",
    "print(\"##########################################################################\")\n",
    "print(\"## 0.2 < z < 0.4 ; 11.4 < logL* < 11.6 using SBP Luminosity\")\n",
    "\n",
    "## Using lum100; model C\n",
    "gamaL2c = gamaTab[(gamaTab['Z'] >= 0.20) & (gamaTab['Z'] <= 0.50) &\n",
    "                  (gamaTab['lum_100'] + (gamaTab['KCORRECT_c_I'] / 2.5) >= 11.4) & \n",
    "                  (gamaTab['lum_100'] + (gamaTab['KCORRECT_c_I'] / 2.5) <= 11.6)]\n",
    "\n",
    "memL2c = memTab[(memTab['Z'] >= 0.20) & (memTab['Z'] <= 0.50) &\n",
    "                (memTab['lum_100'] + (memTab['KCORRECT_c_I'] / 2.5) >= 11.4) & \n",
    "                (memTab['lum_100'] + (memTab['KCORRECT_c_I'] / 2.5) <= 11.6)]\n",
    "\n",
    "bcgL2c = bcgTab[(bcgTab['Z'] >= 0.20) & (bcgTab['Z'] <= 0.50) & \n",
    "                (bcgTab['lum_100'] + (bcgTab['KCORRECT_c_I'] / 2.5) >= 11.4) & \n",
    "                (bcgTab['lum_100'] + (bcgTab['KCORRECT_c_I'] / 2.5) <= 11.6)]\n",
    "\n",
    "## Using lum100; model A\n",
    "gamaL2a = gamaTab[(gamaTab['Z'] >= 0.20) & (gamaTab['Z'] <= 0.50) &\n",
    "                  (gamaTab['lum_100'] + (gamaTab['KCORRECT_I'] / 2.5) >= 11.4) & \n",
    "                  (gamaTab['lum_100'] + (gamaTab['KCORRECT_I'] / 2.5) <= 11.6)]\n",
    "\n",
    "memL2a = memTab[(memTab['Z'] >= 0.20) & (memTab['Z'] <= 0.50) &\n",
    "                (memTab['lum_100'] + (memTab['KCORRECT_I'] / 2.5) >= 11.4) & \n",
    "                (memTab['lum_100'] + (memTab['KCORRECT_I'] / 2.5) <= 11.6)]\n",
    "\n",
    "bcgL2a = bcgTab[(bcgTab['Z'] >= 0.20) & (bcgTab['Z'] <= 0.50) & \n",
    "                (bcgTab['lum_100'] + (bcgTab['KCORRECT_I'] / 2.5) >= 11.4) & \n",
    "                (bcgTab['lum_100'] + (bcgTab['KCORRECT_I'] / 2.5) <= 11.6)]\n",
    "\n",
    "print(\"\\n## GAMA L2 : %i, %i galaxies\" % (len(gamaL2a), len(gamaL2c)))\n",
    "print(\"## BCG L2  : %i, %i galaxies\" % (len(bcgL2a), len(bcgL2c)))\n",
    "print(\"## MEM L2  : %i, %i galaxies\" % (len(memL2a), len(memL2c)))\n",
    "\n",
    "print(\"\\n## GAMA - Median redshift : \", np.nanmedian(gamaL2a['Z']), np.nanmedian(gamaL2c['Z']))\n",
    "print(\"## BCG  - Median redshift : \", np.nanmedian(bcgL2a['Z']), np.nanmedian(bcgL2c['Z']))\n",
    "print(\"## MEM  - Median redshift : \", np.nanmedian(memL2a['Z']), np.nanmedian(memL2c['Z']))\n",
    "\n",
    "print(\"\\n## GAMA - Median logL_sbp : \", (np.nanmedian(gamaL2c['lum_100'] + (gamaL2c['KCORRECT_c_I'] / 2.5))),\n",
    "      (np.nanmedian(gamaL2c['lum_100'] + (gamaL2c['KCORRECT_c_I'] / 2.5))))\n",
    "print(\"## BCG  - Median logL_sbp : \", (np.nanmedian(bcgL2c['lum_100'] + (bcgL2c['KCORRECT_c_I'] / 2.5))),\n",
    "      (np.nanmedian(bcgL2c['lum_100'] + (bcgL2c['KCORRECT_c_I'] / 2.5))))\n",
    "print(\"## MEM  - Median logL_sbp : \", (np.nanmedian(memL2c['lum_100'] + (memL2c['KCORRECT_c_I'] / 2.5))),\n",
    "      (np.nanmedian(memL2c['lum_100'] + (memL2c['KCORRECT_c_I'] / 2.5))))     \n",
    "print(\"##########################################################################\\n\")\n",
    "\n",
    "bcgL2a_pcen = bcgL2a[bcgL2a['P_CEN_1'] >= 0.8]\n",
    "bcgL2c_pcen = bcgL2c[bcgL2c['P_CEN_1'] >= 0.8]\n",
    "\n",
    "print(\"## bcgL2a_pcen : %d out of %d\" % (len(bcgL2a_pcen), len(bcgL2a)))\n",
    "print(\"## bcgL2c_pcen : %d out of %d\" % (len(bcgL2c_pcen), len(bcgL2c)))\n",
    "\n",
    "print(\"## BCG/PCEN - Median redshift : \", np.nanmedian(bcgL2a_pcen['Z']), np.nanmedian(bcgL2c_pcen['Z']))\n",
    "\n",
    "print(\"## BCG/PCEN - Median logL_sbp : \", \n",
    "      (np.nanmedian(bcgL2a_pcen['lum_100'] + (bcgL2a_pcen['KCORRECT_I'] / 2.5))),\n",
    "      (np.nanmedian(bcgL2c_pcen['lum_100'] + (bcgL2c_pcen['KCORRECT_c_I'] / 2.5))))\n",
    "\n",
    "print(\"##########################################################################\\n\")\n",
    "\n",
    "gamaL2c_use = gamaL2c[(gamaL2c['c82_120'] >= 5.0) & (gamaL2c['gz_kC'] >= 1.5)]\n",
    "gamaL2a_use = gamaL2a[(gamaL2a['c82_120'] >= 5.0) & (gamaL2a['gz_kA'] >= 1.5)]\n",
    "\n",
    "print(\"## gamaL2a_pcen : %d out of %d\" % (len(gamaL2a_use), len(gamaL2a)))\n",
    "print(\"## gamaL2c_pcen : %d out of %d\" % (len(gamaL2c_use), len(gamaL2c)))\n",
    "\n",
    "\n",
    "print(\"## GAMA/USE - Median redshift : \", np.nanmedian(gamaL2a_use['Z']), \n",
    "      np.nanmedian(gamaL2c_use['Z']))\n",
    "\n",
    "print(\"## GAMA/USE - Median logL_sbp : \", \n",
    "      (np.nanmedian(gamaL2a_use['lum_100'] + (gamaL2a_use['KCORRECT_I'] / 2.5))),\n",
    "      (np.nanmedian(gamaL2c_use['lum_100'] + (gamaL2c_use['KCORRECT_c_I'] / 2.5))))\n",
    "\n",
    "print(\"##########################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
